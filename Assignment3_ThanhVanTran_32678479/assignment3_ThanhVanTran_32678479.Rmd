---
title: "ETC3250/5250 IML Asignment 3 Solution"
author: "Thanh Van Tran (32678479)"
date: "`r Sys.Date()`"
output:
  html_document:
    code_folding: show
  pdf_document: default
---


```{r, message = FALSE, echo = -1}
knitr::opts_chunk$set(message = FALSE, warning = FALSE)
# Load the packages that you will use to complete this assigment.
library(readr)
library(tidyverse)
library(ggplot2)
library(gridExtra)
library(ggdendro)
library(rpart)
library(rsample)
library(ggdendro)
library(nnet)
library(yardstick)
library(ranger)
library(kknn)
library(pROC)
mydata <- read_csv("data32678479.csv")
```


## Preliminary analysis

### Question 1
What is the letter in your data? (1 mark)

INCLUDE YOUR ANSWER HERE

-  The letter in my data is A, a.

### Question 2
Plot a random sample of 12 images, like below, of your data with the correct orientation. (2 marks)

```{r}
#INCLUDE YOUR R CODE HERE
set.seed(2023)
imagedata_to_plotdata <- function(data,
                                  number_sample, 
                                  w = 28, 
                                  h = 28, 
                                  which = sample(1:nrow(data), number_sample, 
                                                 replace = FALSE)) {
  data %>% 
    mutate(id = 1:n()) %>% 
    filter(id %in% which) %>% 
    pivot_longer(starts_with("V")) %>% 
    mutate(col = rep(rep(1:w, each = h), n_distinct(id)),
           row = rep(rep(1:h, times = w), n_distinct(id)))
}

plot_function <- function(data, number_sample, number_column) {
  set.seed(2023)
  plot_list <- list()
  for (i in 1:number_sample) {
    plot_list[[i]] <- imagedata_to_plotdata(data, number_sample, which = i) %>%
      ggplot(aes(col, row)) +
      geom_tile(aes(fill = value)) +
      scale_y_reverse() +
      theme_void(base_size = 1) +
      guides(fill = "none") +
      coord_equal()
  }
  grid.arrange(grobs = plot_list, ncol = number_column)
}
plot_function(mydata, 12, 4)
```

### Question 3
Perform a principal component analysis (PCA) on your data. How much variation does the first 5 principal components explain in the data? (2 marks)

```{r}
#INCLUDE YOUR R CODE HERE
mydata_pca <- prcomp(mydata, scale = FALSE)
var_mydata_pca <- mydata_pca$sdev^2
var_first_five_pca <- sum(var_mydata_pca[1:5])
proportion <- var_first_five_pca/sum(var_mydata_pca)
proportion
```

INCLUDE YOUR ANSWER HERE

### Question 4
Show what aspect of the data the first and second principal component loadings capture like the example plot below. (2 marks)

```{r}
#INCLUDE YOUR R CODE HERE
set.seed(2023)
Xnew_pca1 <- mydata_pca$x[, 1] %*% t(mydata_pca$rotation[, 1])
Pdata_pca1 <- as.data.frame(Xnew_pca1)
plot_function(Pdata_pca1, 1, 1)

Xnew_pca2 <- mydata_pca$x[, 2] %*% t(mydata_pca$rotation[, 2])
Pdata_pca2 <- as.data.frame(Xnew_pca2)
plot_function(Pdata_pca2, 1, 1)
```

### Question 5
Using the rotated data from the PCA, perform an agglomeration hierarchical clustering with average linkage. (2 marks)
```{r}
#INCLUDE YOUR R CODE HERE
haverage <- hclust(dist(mydata_pca$x), method = "average")
```

### Question 6
Cut the tree from question 5 to 4 clusters. Show how many observations you have per cluster. (2 marks)
```{r}
#INCLUDE YOUR R CODE HERE
caverage <- cutree(haverage, k = 4)
table(caverage)
```
The output shows that the first cluster contains 3376 observations, the second cluster contains 13 observations, and the third and the fourth clusters each contain only one observation. 

### Question 7
Show a sample of 10 (or the total number of images in a cluster if less than 10 observations in a cluster) images from each cluster like the plot below. What do you notice about the cluster groups? (3 marks)
```{r}
#INCLUDE YOUR R CODE HERE
set.seed(2023)
cluster1_data <- mydata[caverage == 1, ]
plot1 <- plot_function(cluster1_data, 10, 1)

cluster2_data <- mydata[caverage == 2, ]
plot2 <- plot_function(cluster2_data, 10, 1)

cluster3_data <- mydata[caverage == 3, ]
plot3 <-plot_function(cluster3_data, 1, 1)

cluster4_data <- mydata[caverage == 4, ]
plot4 <- plot_function(cluster4_data, 1, 1)

grid.arrange(plot1, plot2, plot3, plot4, ncol=4)
```

INCLUDE YOUR ANSWER HERE

After reducing the number of clusters from 5 to 4 in the decision tree, we randomly plotted 10 observations from each cluster and observed some interesting patterns.

- Although the observations in cluster 1 were generally represented with a thinner line compared to those in cluster 2 which were represented with a thicker line. However, there were still some thick observations in cluster 1 and thin observations in cluster 2.

- Additionally, one observation in cluster 4 was much larger and did not fit within the range of the plot.

- Another issue was that cluster 1 had a significantly larger number of observations (3376 observations) compared to clusters 2, 3, and 4 which only had 13, 1, and 1 observation(s) respectively. 

- Lastly, we also noticed that there is one distinguish feature of the observations which is capital letter (A) and normal letter (a). However, this method did not appear to classify this important feature well.

- In conclusion, based on these observations, it is clear that the agglomeration hierarchical clustering with average linkage may not perform well and other methods should be explored to better categories the observations.


## Report
WRITE YOUR REPORT HERE
```{r, class.source = 'fold-hide'}
#Ward's method
hward <- hclust(dist(mydata_pca$x), method = "ward.D2")
#cutting the tree
#ggdendrogram(hward, rotate = TRUE) + labs(title = "Ward's method")
cward <- cutree(hward, k = 5)
table(cward)
#plot to see the cluster
set.seed(2023)
cluster1_ward <- mydata[cward == 1, ]
plot1_ward <- plot_function(cluster1_ward, 10, 10)

cluster2_ward <- mydata[cward == 2, ]
plot2_ward <- plot_function(cluster2_ward, 10, 10)

cluster3_ward <- mydata[cward == 3, ]
plot3_ward <-plot_function(cluster3_ward, 10, 10)

cluster4_ward <- mydata[cward == 4, ]
plot4_ward <- plot_function(cluster4_ward, 10, 10)

cluster5_ward <- mydata[cward == 5, ]
plot5_ward <- plot_function(cluster5_ward, 10, 10)
```


```{r, class.source = 'fold-hide'}
#combine the response variable and predict variable into dataframe
mydata_train <- as.data.frame(cbind(cward, mydata_pca$x))
#split the data into training and testing set
set.seed(2023)
mydata_split<- initial_split(mydata_train)
mydata_training <- training(mydata_split)
mydata_testing <- testing(mydata_split)
```


```{r, class.source = 'fold-hide'}
#model 1: kNN
mydata_train_knn <- as.data.frame(cbind(cward, mydata_pca$x))
mydata_train_knn$cward <- as.factor(mydata_train_knn$cward)
#split the data into training and testing set
set.seed(2023)
mydata_split_knn <- initial_split(mydata_train_knn)
mydata_training_knn <- training(mydata_split_knn)
mydata_testing_knn <- testing(mydata_split_knn)

knn_pred <- kknn(cward ~.,
                 train = mydata_training_knn,
                 test =  mydata_testing_knn,
                 k = 2,
                 distance = 2)
```

```{r, class.source = 'fold-hide'}
#model 2: Random Forest
class_rf <- ranger(cward ~ ., 
                   data = mydata_training,
                   mtry = floor((ncol(mydata_training) - 1) / 3),
                   num.trees = 500,
                   classification = TRUE)
rf_pred <- predict(class_rf, data = mydata_testing)
rf_pred_newdata <- mydata_testing %>% mutate(Prediction = rf_pred$predictions)
```

COMPARE MODEL PERFORMANCE BY METRICS
```{r, class.source = 'fold-hide'}
#Compare 2 model's performance
model_testing <- mydata_testing %>% select(cward) %>% 
                    mutate (random_forest = factor(rf_pred$predictions),
                            knn = factor(knn_pred$fitted.values))
model_testing$cward <- as.factor(model_testing$cward)

rf_metric <- 
  metric_set(accuracy, bal_accuracy, kap)(model_testing, truth = cward, 
                                          estimate = random_forest)
knn_metric <- 
  metric_set(accuracy, bal_accuracy, kap)(model_testing, truth = cward, 
                                          estimate = knn)
metric_list <- list(
  rf_metric,
  knn_metric
)
# combine the metrics into a table
result_table <- bind_rows(metric_list, .id = "model") %>%
  mutate(model = case_when(
    model == "1" ~ "Random Forest",
    model == "2" ~ "K-Nearest Neighbors")) %>%
  pivot_wider(id_cols = model, names_from = .metric, values_from = .estimate)

result_table
```

VISUALISE NEW DATA
```{r, class.source = 'fold-hide'}
#new data 
new_data <- read_csv("newrecords32678479.csv")
imagedata_to_plotdata_newdata <- function(data = new_data,
                                  w = 28, 
                                  h = 28, 
                                  which = 1:nrow(data)) {
  data %>% 
    mutate(id = 1:n()) %>% 
    filter(id %in% which) %>% 
    pivot_longer(starts_with("V")) %>% 
    mutate(col = rep(rep(1:w, each = h), n_distinct(id)),
           row = rep(rep(1:h, times = w), n_distinct(id)))
}
gletter <- imagedata_to_plotdata_newdata(new_data) %>% 
    ggplot(aes(col, row)) +
    geom_tile(aes(fill = value)) +
    scale_y_reverse() +
    facet_wrap(~id, nrow = 1) +
    theme_void(base_size = 18) +
    guides(fill = "none") +
    coord_equal()
gletter
```

PREDICTION ON NEW DATA 
```{r, class.source = 'fold-hide'}
#PCA on new_data
newdata_pca <- predict(mydata_pca, newdata = new_data)
data_pred <- as.data.frame(newdata_pca)

#model 1: random forest
class_rf_predict <- ranger(cward ~ ., 
                   data = mydata_train,
                   mtry = floor((ncol(mydata_train) - 1) / 3),
                   num.trees = 500,
                   classification = TRUE)
newdata_predict_rf <- predict(class_rf_predict, data = data_pred)
newdata_predict_rf$predictions 
```
- The Ward method was used to cluster the observations, and the resulting tree was visualized using the ggdendrogram. Based on the gap in the dendrogram, a decision was made to cut the tree into 5 groups. This decision was made because the gap at this point was not too short, indicating a distinguishable difference between these groups.

- Based on the clustering results, observations containing the normal letter "a" are grouped into cluster 1, cluster 3, and cluster 5. Cluster 2 and cluster 4 combine the observations containing the capital letter "A".

-  However, there are noticeable differences between these clusters. The "a" in cluster 1 and cluster 3 was written in the same way, but the "a" in cluster 1 is rounder, bigger, clearer, and has a thicker line than the "a" in cluster 3. Meanwhile, the "a" in cluster 5 was written in a completely different way.

-  Cluster 2 and cluster 4 combine the observations containing the capital letter "A". The "A" in cluster 2 is straighter, larger, and clearer than the "A" in cluster 4, which leans to the right and is thinner. In summary, the clustering by the Ward method results show that there are noticeable differences in the way that the letters "a" and "A" are written across different clusters, with variations in size, shape, and clarity.

-  Supervised learning techniques were employed using principal components as predictors and clusters as the response variable. The original dataset was split into training and testing datasets to evaluate the performance of different models. Random forest and k-nearest neighbor algorithms were used to model the training dataset, with the trained models then applied to the testing dataset.

-  To assess the performance of the models, accuracy, balanced accuracy, and Cohen's kappa coefficient were used as metrics. Ultimately, the random forest algorithm was found to outperform the other methods, making it the chosen algorithm for predicting the cluster to which each new observation belongs. Ultimately, the random forest algorithm outperforms the another method, hence, it is chose to predict the cluster that each new observations belong to. 

-  After training the principal component analysis on the original dataset, it will be applied to a new dataset. Subsequently, the random forest model will be used to predict the cluster of the new observations.

-  The random forest model predicts that the first observation belongs to cluster 3, while the remaining observations belong to cluster 2.

-  The first observation was correctly predicted to be in cluster 3, which corresponds to smaller "a" with a thinner line. The second, fourth, and fifth observations were predicted to be in cluster 2, as they are straight and not leaning towards the right. Although the fifth observation is slightly leaning to the right, it is not significant enough to be placed in cluster 3.

-  However, the method did not cluster the third observation accurately. The third observation has a similar presentation to the observations in cluster 5, but it was assigned to cluster 2. This could be because there are only 296 observations in cluster 5, which might not capture all the variation of this kind of "a" presentation.

-  Overall, the method performs well in predicting the new observations, except for cluster 5. This may be due to the limited number of observations in this cluster, and there is room for improvement in predicting this cluster such as adding more observations have this kind of "a" presentation.



